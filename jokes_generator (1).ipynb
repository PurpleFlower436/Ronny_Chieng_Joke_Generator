{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq openai"
      ],
      "metadata": {
        "id": "hCU6Ixax4awy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "947b33b1-9924-4b27-b296-4b7b06fcf821"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "yBv-VZMX4a0P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-nXDa3xWf6A",
        "outputId": "460c7dad-9afe-439b-8eb4-b7298894094b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_XsEdMrWgi9",
        "outputId": "7076724a-b0b8-416b-a6a1-302c37bade55"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai tools fine_tunes.prepare_data -f \"/content/drive/MyDrive/TheDailyShow_Jokes.xlsx\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVs4vseP4a2_",
        "outputId": "7ce93d1f-18b1-415f-98ff-7d53f1605c00"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Based on your file extension, your file is formatted as an Excel file\n",
            "- Your file contains 19 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
            "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
            "- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Necessary] Your format `XLSX` will be converted to `JSONL`\n",
            "- [Recommended] Add a suffix separator `\\n\\n###\\n\\n` to all prompts [Y/n]: Y\n",
            "- [Recommended] Add a suffix ending ` END` to all completions [Y/n]: Y\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
            "\n",
            "Wrote modified file to `/content/drive/MyDrive/TheDailyShow_Jokes_prepared (2).jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"/content/drive/MyDrive/TheDailyShow_Jokes_prepared (2).jsonl\"\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\" END\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 2.7 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.File.create(file=open(\"TheDailyShow_Jokes_prepared (2).jsonl\", \"rb\"), purpose='fine-tune')"
      ],
      "metadata": {
        "id": "pRkldtkKndGJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_pW_kk2nt1j",
        "outputId": "2b00e048-4ad5-4f23-e81b-74f73abb1213"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"object\": \"file\",\n",
            "  \"id\": \"file-Rpg01jSUSAm3W7RVjS53Ql0P\",\n",
            "  \"purpose\": \"fine-tune\",\n",
            "  \"filename\": \"file\",\n",
            "  \"bytes\": 11835,\n",
            "  \"created_at\": 1697982163,\n",
            "  \"status\": \"uploaded\",\n",
            "  \"status_details\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = \"file-Rpg01jSUSAm3W7RVjS53Ql0P\"\n",
        "response = openai.FineTuningJob.create(training_file=file_id, model=\"babbage-002\")\n",
        "\n"
      ],
      "metadata": {
        "id": "RqCxKem-oIUs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF5s0YvZoe3a",
        "outputId": "a3c39f11-da14-46dc-8c97-3483f17005ce"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"object\": \"fine_tuning.job\",\n",
            "  \"id\": \"ftjob-lymz1FbmUmnpt2LFlUpiNufy\",\n",
            "  \"model\": \"babbage-002\",\n",
            "  \"created_at\": 1697982474,\n",
            "  \"finished_at\": null,\n",
            "  \"fine_tuned_model\": null,\n",
            "  \"organization_id\": \"org-n0ogwTNZrxw4iinCMpxpJnEe\",\n",
            "  \"result_files\": [],\n",
            "  \"status\": \"validating_files\",\n",
            "  \"validation_file\": null,\n",
            "  \"training_file\": \"file-Rpg01jSUSAm3W7RVjS53Ql0P\",\n",
            "  \"hyperparameters\": {\n",
            "    \"n_epochs\": \"auto\"\n",
            "  },\n",
            "  \"trained_tokens\": null,\n",
            "  \"error\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Generate a joke in the style of Ronny Chieng based on the following headline: As China strengthens ties with Russia, the Israel-Hamas war deepens their divide with the U.S. \\n\\n###\\n\\n\""
      ],
      "metadata": {
        "id": "gQccr_iNyzz_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"ft:babbage-002:personal::8CT7RlBC\",\n",
        "  prompt=prompt,\n",
        "  max_tokens=200,\n",
        "  temperature=0.4,\n",
        "  top_p=1,\n",
        "  n=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\" END\"]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vWUdWaMcpv8_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "BkupWTnryz5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aa44735-df4b-49ad-b144-aa6e4ccb085d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " As China strengthens ties with Russia, the Israel-Hamas war deepens their divide with the U.S. A new report says that China's growing ties with Russia could be putting a strain on U.S.-Russia relations. But it turns out that the real conflict is over Israel's relationship with the U.S. It's a battle that's been going on for decades, and it looks like it's about to get even more intense. It all started with the Berlin Wall. Then, the Soviet Union collapsed, and the U.S. and the Soviet Union fought a Cold War. But now, China and Russia are fighting a new kind of Cold War. It's called the Israel-Hamas War. It started in 2014 when Israeli Prime Minister Benjamin Netanyahu decided to build a new settlement in the West Bank. But instead of building a new settlement, he decided to build a new city. And that's when the conflict started. Israel's Prime Minister Benjamin Netanyahu is building a new city in the\n"
          ]
        }
      ]
    }
  ]
}